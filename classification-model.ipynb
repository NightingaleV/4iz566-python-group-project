{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Supress Notebook Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>3.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1783.791667</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>12.241717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>184.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>4.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>New_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "12325             3.0                    145.0            0.0   \n",
       "12326             0.0                      0.0            0.0   \n",
       "12327             0.0                      0.0            0.0   \n",
       "12328             4.0                     75.0            0.0   \n",
       "12329             0.0                      0.0            0.0   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "12325                     0.0            53.0              1783.791667   \n",
       "12326                     0.0             5.0               465.750000   \n",
       "12327                     0.0             6.0               184.250000   \n",
       "12328                     0.0            15.0               346.000000   \n",
       "12329                     0.0             3.0                21.250000   \n",
       "\n",
       "       BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "12325     0.007143   0.029031   12.241717         0.0   Dec                 4   \n",
       "12326     0.000000   0.021333    0.000000         0.0   Nov                 3   \n",
       "12327     0.083333   0.086667    0.000000         0.0   Nov                 3   \n",
       "12328     0.000000   0.021053    0.000000         0.0   Nov                 2   \n",
       "12329     0.000000   0.066667    0.000000         0.0   Nov                 3   \n",
       "\n",
       "       Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "12325        6       1            1  Returning_Visitor     True    False  \n",
       "12326        2       1            8  Returning_Visitor     True    False  \n",
       "12327        2       1           13  Returning_Visitor     True    False  \n",
       "12328        2       3           11  Returning_Visitor    False    False  \n",
       "12329        2       1            2        New_Visitor     True    False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('data/online_shoppers_intention.csv', delimiter=',')\n",
    "df_raw.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative             14\n",
       "Administrative_Duration    14\n",
       "Informational              14\n",
       "Informational_Duration     14\n",
       "ProductRelated             14\n",
       "ProductRelated_Duration    14\n",
       "BounceRates                14\n",
       "ExitRates                  14\n",
       "PageValues                  0\n",
       "SpecialDay                  0\n",
       "Month                       0\n",
       "OperatingSystems            0\n",
       "Browser                     0\n",
       "Region                      0\n",
       "TrafficType                 0\n",
       "VisitorType                 0\n",
       "Weekend                     0\n",
       "Revenue                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show counter for null values\n",
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12316.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.317798</td>\n",
       "      <td>80.906176</td>\n",
       "      <td>0.503979</td>\n",
       "      <td>34.506387</td>\n",
       "      <td>31.763884</td>\n",
       "      <td>1196.037057</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>5.889258</td>\n",
       "      <td>0.061427</td>\n",
       "      <td>2.124006</td>\n",
       "      <td>2.357097</td>\n",
       "      <td>3.147364</td>\n",
       "      <td>4.069586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.322754</td>\n",
       "      <td>176.860432</td>\n",
       "      <td>1.270701</td>\n",
       "      <td>140.825479</td>\n",
       "      <td>44.490339</td>\n",
       "      <td>1914.372511</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.048527</td>\n",
       "      <td>18.568437</td>\n",
       "      <td>0.198917</td>\n",
       "      <td>0.911325</td>\n",
       "      <td>1.717277</td>\n",
       "      <td>2.401591</td>\n",
       "      <td>4.025169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>599.766190</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1466.479902</td>\n",
       "      <td>0.016684</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>3398.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2549.375000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>63973.522230</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>361.763742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "count    12316.000000             12316.000000   12316.000000   \n",
       "mean         2.317798                80.906176       0.503979   \n",
       "std          3.322754               176.860432       1.270701   \n",
       "min          0.000000                -1.000000       0.000000   \n",
       "25%          0.000000                 0.000000       0.000000   \n",
       "50%          1.000000                 8.000000       0.000000   \n",
       "75%          4.000000                93.500000       0.000000   \n",
       "max         27.000000              3398.750000      24.000000   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "count            12316.000000    12316.000000             12316.000000   \n",
       "mean                34.506387       31.763884              1196.037057   \n",
       "std                140.825479       44.490339              1914.372511   \n",
       "min                 -1.000000        0.000000                -1.000000   \n",
       "25%                  0.000000        7.000000               185.000000   \n",
       "50%                  0.000000       18.000000               599.766190   \n",
       "75%                  0.000000       38.000000              1466.479902   \n",
       "max               2549.375000      705.000000             63973.522230   \n",
       "\n",
       "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
       "count  12316.000000  12316.000000  12330.000000  12330.000000   \n",
       "mean       0.022152      0.043003      5.889258      0.061427   \n",
       "std        0.048427      0.048527     18.568437      0.198917   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.014286      0.000000      0.000000   \n",
       "50%        0.003119      0.025124      0.000000      0.000000   \n",
       "75%        0.016684      0.050000      0.000000      0.000000   \n",
       "max        0.200000      0.200000    361.763742      1.000000   \n",
       "\n",
       "       OperatingSystems       Browser        Region   TrafficType  \n",
       "count      12330.000000  12330.000000  12330.000000  12330.000000  \n",
       "mean           2.124006      2.357097      3.147364      4.069586  \n",
       "std            0.911325      1.717277      2.401591      4.025169  \n",
       "min            1.000000      1.000000      1.000000      1.000000  \n",
       "25%            2.000000      2.000000      1.000000      2.000000  \n",
       "50%            2.000000      2.000000      3.000000      2.000000  \n",
       "75%            3.000000      2.000000      4.000000      4.000000  \n",
       "max            8.000000     13.000000      9.000000     20.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problematic Rows Count: 33\n"
     ]
    }
   ],
   "source": [
    "# Rows with negative duration\n",
    "print('Problematic Rows Count:',df_raw[df_raw['Informational_Duration'] < 0].count()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Try Oversampling / Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/saurav9786/ensemble-techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove rows with null & negative value\n",
    "df = df_raw[((df_raw['Administrative_Duration'] >= 0) & (df_raw['Informational_Duration'] >= 0) & (df_raw['ProductRelated_Duration'] >= 0))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    3357\n",
       "7    2995\n",
       "5    1884\n",
       "1    1727\n",
       "8     549\n",
       "9     448\n",
       "0     433\n",
       "3     431\n",
       "4     288\n",
       "2     171\n",
       "Name: Month, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Month']= df['Month'].astype('category').cat.codes\n",
    "df['Month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Binary Encoding\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# From Label to Boolean\n",
    "df['Revenue'] = label_binarize(df['Revenue'], classes=[False,True])\n",
    "df['Weekend'] = label_binarize(df['Weekend'], classes=[False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12325</th>\n",
       "      <td>3.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1783.791667</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.029031</td>\n",
       "      <td>12.241717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12326</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12327</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>184.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12328</th>\n",
       "      <td>4.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12329</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>New_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "12325             3.0                    145.0            0.0   \n",
       "12326             0.0                      0.0            0.0   \n",
       "12327             0.0                      0.0            0.0   \n",
       "12328             4.0                     75.0            0.0   \n",
       "12329             0.0                      0.0            0.0   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "12325                     0.0            53.0              1783.791667   \n",
       "12326                     0.0             5.0               465.750000   \n",
       "12327                     0.0             6.0               184.250000   \n",
       "12328                     0.0            15.0               346.000000   \n",
       "12329                     0.0             3.0                21.250000   \n",
       "\n",
       "       BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "12325     0.007143   0.029031   12.241717         0.0   Dec                 4   \n",
       "12326     0.000000   0.021333    0.000000         0.0   Nov                 3   \n",
       "12327     0.083333   0.086667    0.000000         0.0   Nov                 3   \n",
       "12328     0.000000   0.021053    0.000000         0.0   Nov                 2   \n",
       "12329     0.000000   0.066667    0.000000         0.0   Nov                 3   \n",
       "\n",
       "       Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "12325        6       1            1  Returning_Visitor     True    False  \n",
       "12326        2       1            8  Returning_Visitor     True    False  \n",
       "12327        2       1           13  Returning_Visitor     True    False  \n",
       "12328        2       3           11  Returning_Visitor    False    False  \n",
       "12329        2       1            2        New_Visitor     True    False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Boolean Cols from Cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Boolean - Visited the type of page\n",
    "df['Administrative_Visited'] = np.where(df['Administrative'] > 1, 1,0)\n",
    "df['Informational_Visited'] = np.where(df['Informational'] > 1, 1,0)\n",
    "df['ProductRelated_Visited'] = np.where(df['ProductRelated'] > 1, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsSpecialDate'] = np.where(df['SpecialDay'] > 1, 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    8189\n",
       " 1    2255\n",
       " 2    1057\n",
       " 3     483\n",
       " 4     186\n",
       " 5      78\n",
       " 6      20\n",
       " 7       9\n",
       "-1       6\n",
       "Name: Administrative_Bins, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Administrative\n",
    "column_name = 'Administrative'\n",
    "interval_step = 3\n",
    "new_column_name = column_name + '_Bins'\n",
    "interval = range(0, int(max(df[column_name])), interval_step)\n",
    "max_number_of_intervals =  10\n",
    "\n",
    "# Create Column\n",
    "df[new_column_name] = pd.cut(df[column_name], interval, right=False)\n",
    "df[new_column_name] = df[new_column_name].astype('category').cat.codes\n",
    "df.loc[(df[new_column_name].astype('category').cat.codes >= max_number_of_intervals),new_column_name] = max_number_of_intervals\n",
    "df[new_column_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0     8235\n",
       " 1     2329\n",
       " 2      826\n",
       " 3      380\n",
       " 4      201\n",
       " 5      120\n",
       " 10      70\n",
       " 6       53\n",
       " 7       46\n",
       " 8       22\n",
       "-1        1\n",
       "Name: ProductRelated_Bins, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ProductRelated\n",
    "column_name = 'ProductRelated'\n",
    "interval_step = 30\n",
    "new_column_name = column_name + '_Bins'\n",
    "interval = range(0, int(max(df[column_name])), interval_step)\n",
    "max_number_of_intervals =  10\n",
    "\n",
    "# Create Column\n",
    "df[new_column_name] = pd.cut(df[column_name], interval, right=False)\n",
    "df[new_column_name] = df[new_column_name].astype('category').cat.codes\n",
    "df.loc[(df[new_column_name].astype('category').cat.codes >= max_number_of_intervals),new_column_name] = max_number_of_intervals\n",
    "df[new_column_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy columns\n",
    "Drop is manual, because we often want to keep the first column and drop the last one, which is often group of nonlabeled elements ('Others')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Returning_Visitor', 'New_Visitor', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.VisitorType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['VisitorType'], drop_first=False)\n",
    "df = df.drop(['VisitorType_Other'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['TrafficType'], drop_first=False)\n",
    "df = df.drop(['TrafficType_20'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['OperatingSystems'], drop_first=False)\n",
    "df = df.drop(['OperatingSystems_8'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Browser'], drop_first=False)\n",
    "df = df.drop(['Browser_13'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Region'], drop_first=False)\n",
    "df = df.drop(['Region_9'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int8'), dtype('int64'), dtype('uint8')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Administrative', 'Administrative_Duration', 'Informational',\n",
       "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
       "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month',\n",
       "       'Weekend', 'Revenue', 'Administrative_Visited', 'Informational_Visited',\n",
       "       'ProductRelated_Visited', 'IsSpecialDate', 'Administrative_Bins',\n",
       "       'ProductRelated_Bins', 'VisitorType_New_Visitor',\n",
       "       'VisitorType_Returning_Visitor', 'TrafficType_1', 'TrafficType_2',\n",
       "       'TrafficType_3', 'TrafficType_4', 'TrafficType_5', 'TrafficType_6',\n",
       "       'TrafficType_7', 'TrafficType_8', 'TrafficType_9', 'TrafficType_10',\n",
       "       'TrafficType_11', 'TrafficType_12', 'TrafficType_13', 'TrafficType_14',\n",
       "       'TrafficType_15', 'TrafficType_16', 'TrafficType_17', 'TrafficType_18',\n",
       "       'TrafficType_19', 'OperatingSystems_1', 'OperatingSystems_2',\n",
       "       'OperatingSystems_3', 'OperatingSystems_4', 'OperatingSystems_5',\n",
       "       'OperatingSystems_6', 'OperatingSystems_7', 'Browser_1', 'Browser_2',\n",
       "       'Browser_3', 'Browser_4', 'Browser_5', 'Browser_6', 'Browser_7',\n",
       "       'Browser_8', 'Browser_9', 'Browser_10', 'Browser_11', 'Browser_12',\n",
       "       'Region_1', 'Region_2', 'Region_3', 'Region_4', 'Region_5', 'Region_6',\n",
       "       'Region_7', 'Region_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10375\n",
       "1     1908\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_VARIABLE = 'Revenue'\n",
    "TEST_SIZE = 0.3\n",
    "df[TARGET_VARIABLE].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels=[TARGET_VARIABLE], axis=1)\n",
    "y = df[TARGET_VARIABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=RANDOM_STATE)\n",
    "\n",
    "def print_acc_score(y_test, predictions):\n",
    "    print(\"Accuracy: {:.2%}\".format(accuracy_score(y_test, predictions))) \n",
    "\n",
    "def print_cv_score(cv_score):\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f with 95 % confidence)\" % (cv_score.mean(), cv_score.std() * 2))\n",
    "    \n",
    "    #print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_acc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Metrics - Evaluation Matrix\n",
    "### Metrics\n",
    "- Recall\n",
    "- Precision\n",
    "- F1 Score\n",
    "To gather the evaluation results from different models into one df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>EvaluationInfo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False_Precision</th>\n",
       "      <th>True_Precision</th>\n",
       "      <th>True_Recall</th>\n",
       "      <th>True_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, EvaluationInfo, Accuracy, False_Precision, True_Precision, True_Recall, True_F1_Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_matrix_columns = ['Model',\n",
    "                             'EvaluationInfo',\n",
    "                             'Accuracy',\n",
    "                             'False_Precision',\n",
    "                             'True_Precision',\n",
    "                             'True_Recall',\n",
    "                             'True_F1_Score']\n",
    "\n",
    "evaluation_matrix = pd.DataFrame(columns = evaluation_matrix_columns)\n",
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model and Add results to the matrix\n",
    "def evaluate_model(model, y_test, y_pred, evaluation_info=''):\n",
    "    global evaluation_matrix\n",
    "    float_precision = 3\n",
    "    total_accuracy  = round(100 * accuracy_score(y_test, y_pred), float_precision)\n",
    "    false_precision = round(100 * precision_score(y_test,y_pred, pos_label=0, average='binary'), float_precision)\n",
    "    true_precision  = round(100 * precision_score(y_test,y_pred, pos_label=1, average='binary'), float_precision)\n",
    "    true_recall     = round(100 * recall_score(y_test,y_pred, pos_label=1, average='binary'), float_precision)\n",
    "    true_f1_beta    = round(100 * fbeta_score(y_test, y_pred, beta=1.5), float_precision)\n",
    "    \n",
    "    model_evaluation_dict = {'Model':model.__class__.__name__,\n",
    "                             'EvaluationInfo':evaluation_info,\n",
    "                             'Accuracy':total_accuracy,\n",
    "                             'False_Precision':false_precision,\n",
    "                             'True_Precision':true_precision,\n",
    "                             'True_Recall':true_recall,\n",
    "                             'True_F1_Score':true_f1_beta}\n",
    "    evaluation_matrix = evaluation_matrix.append(model_evaluation_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>EvaluationInfo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False_Precision</th>\n",
       "      <th>True_Precision</th>\n",
       "      <th>True_Recall</th>\n",
       "      <th>True_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, EvaluationInfo, Accuracy, False_Precision, True_Precision, True_Recall, True_F1_Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Implement Cross validation\n",
    "# cross_val_score(gaussiannb, X_train, y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - Pick right Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier\n",
    "- Most basic models that are used as a baseline models for the clasification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Frequent\n",
    "- Is taking most frequent class for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dummy_clf_mf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf_mf.fit(X, y)\n",
    "y_pred = dummy_clf_mf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      3105\n",
      "           1       0.00      0.00      0.00       580\n",
      "\n",
      "    accuracy                           0.84      3685\n",
      "   macro avg       0.42      0.50      0.46      3685\n",
      "weighted avg       0.71      0.84      0.77      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(dummy_clf_mf,y_test,y_pred,'most_frequent')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified\n",
    "- Keep the ratio of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      3105\n",
      "           1       0.15      0.15      0.15       580\n",
      "\n",
      "    accuracy                           0.73      3685\n",
      "   macro avg       0.49      0.49      0.49      3685\n",
      "weighted avg       0.73      0.73      0.73      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_clf_st = DummyClassifier(strategy=\"stratified\")\n",
    "dummy_clf_st.fit(X, y)\n",
    "y_pred = dummy_clf_st.predict(X_test)\n",
    "\n",
    "evaluate_model(dummy_clf_st,y_test,y_pred,'stratified')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7305291723202171"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "- (https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the Y variable has a high class imbalance. Hence accuracy will not be a reliable model performance measure.\n",
    "\n",
    "FN is very critical for this business case because a false negative is a customer who will potentially subscribe for a loan but who has been classified as 'will not subscribe'. Hence the most relevant model performance measure is recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      3105\n",
      "           1       0.58      0.54      0.56       580\n",
      "\n",
      "    accuracy                           0.86      3685\n",
      "   macro avg       0.75      0.73      0.74      3685\n",
      "weighted avg       0.86      0.86      0.86      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion='gini', splitter='best', random_state=RANDOM_STATE)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = dtree.predict(X_test)\n",
    "evaluate_model(dtree,y_test,y_pred,'gini')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      3105\n",
      "           1       0.57      0.54      0.56       580\n",
      "\n",
      "    accuracy                           0.86      3685\n",
      "   macro avg       0.74      0.73      0.74      3685\n",
      "weighted avg       0.86      0.86      0.86      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion='entropy', splitter='best', random_state=RANDOM_STATE)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = dtree.predict(X_test)\n",
    "evaluate_model(dtree,y_test,y_pred,'entropy')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>EvaluationInfo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False_Precision</th>\n",
       "      <th>True_Precision</th>\n",
       "      <th>True_Recall</th>\n",
       "      <th>True_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gini</td>\n",
       "      <td>86.486</td>\n",
       "      <td>91.473</td>\n",
       "      <td>57.565</td>\n",
       "      <td>53.793</td>\n",
       "      <td>54.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>entropy</td>\n",
       "      <td>86.459</td>\n",
       "      <td>91.523</td>\n",
       "      <td>57.404</td>\n",
       "      <td>54.138</td>\n",
       "      <td>55.103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model EvaluationInfo  Accuracy  False_Precision  \\\n",
       "2  DecisionTreeClassifier           gini    86.486           91.473   \n",
       "3  DecisionTreeClassifier        entropy    86.459           91.523   \n",
       "\n",
       "   True_Precision  True_Recall  True_F1_Score  \n",
       "2          57.565       53.793         54.900  \n",
       "3          57.404       54.138         55.103  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_matrix.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3105\n",
      "           1       0.81      0.51      0.63       580\n",
      "\n",
      "    accuracy                           0.91      3685\n",
      "   macro avg       0.86      0.75      0.79      3685\n",
      "weighted avg       0.90      0.91      0.90      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ran_forest = RandomForestClassifier(n_estimators=500, min_samples_split=3, random_state=RANDOM_STATE,\n",
    "                                   bootstrap=True,)\n",
    "ran_forest.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = ran_forest.predict(X_test)\n",
    "evaluate_model(ran_forest,y_test,y_pred,'n_estimators=500')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      3105\n",
      "           1       0.35      0.67      0.46       580\n",
      "\n",
      "    accuracy                           0.75      3685\n",
      "   macro avg       0.64      0.72      0.65      3685\n",
      "weighted avg       0.83      0.75      0.78      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussiannb= GaussianNB()\n",
    "gaussiannb.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = gaussiannb.predict(X_test)\n",
    "evaluate_model(gaussiannb,y_test,y_pred,'')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95      3105\n",
      "           1       0.78      0.57      0.66       580\n",
      "\n",
      "    accuracy                           0.91      3685\n",
      "   macro avg       0.85      0.77      0.80      3685\n",
      "weighted avg       0.90      0.91      0.90      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbk = GradientBoostingClassifier(learning_rate=0.01, n_estimators=500,random_state=RANDOM_STATE)\n",
    "gbk.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = gbk.predict(X_test)\n",
    "evaluate_model(gbk,y_test,y_pred,'n_estimators=500')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      3105\n",
      "           1       0.72      0.25      0.37       580\n",
      "\n",
      "    accuracy                           0.87      3685\n",
      "   macro avg       0.80      0.62      0.65      3685\n",
      "weighted avg       0.85      0.87      0.84      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),n_estimators=500,\n",
    "                            max_samples=0.9, max_features=0.9,bootstrap=True,\n",
    "                            bootstrap_features=False)\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "y_pred = bagging.predict(X_test)\n",
    "evaluate_model(bagging,y_test,y_pred,'n_estimators=500')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(GradientBoostingClassifier(),n_estimators=20,\n",
    "                            max_samples=0.9, max_features=0.9,bootstrap=True,\n",
    "                            bootstrap_features=False)\n",
    "bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bagging.predict(X_test)\n",
    "evaluate_model(bagging,y_test,y_pred,'n_estimators=50')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3044   61]\n",
      " [ 352  228]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3105\n",
      "           1       0.79      0.39      0.52       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.84      0.69      0.73      3685\n",
      "weighted avg       0.88      0.89      0.87      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression(solver='liblinear', C=19.1, penalty='l1',random_state=RANDOM_STATE)\n",
    "logmodel.fit(X, y)\n",
    "\n",
    "# Test\n",
    "y_pred = logmodel.predict(X_test)\n",
    "evaluate_model(logmodel,y_test,y_pred,'C=19.1, penalty=l1')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict_proba\n",
    "Returns\n",
    "Tarray-like of shape (n_samples, n_classes)\n",
    "Returns the probability of the sample for each class in the model, where classes are ordered as they are in self.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07423112, 0.0139902 , 0.33429053, ..., 0.03999546, 0.09052969,\n",
       "       0.16198218])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get probabilities for Revenue = 1\n",
    "y_prob_pred = logmodel.predict_proba(X_test)[:,1]\n",
    "y_prob_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LG: Probability Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG with threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      3105\n",
      "           1       0.62      0.72      0.67       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.79      0.82      0.80      3685\n",
      "weighted avg       0.90      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      3105\n",
      "           1       0.67      0.61      0.64       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.80      0.78      0.79      3685\n",
      "weighted avg       0.89      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      3105\n",
      "           1       0.70      0.54      0.61       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.81      0.75      0.77      3685\n",
      "weighted avg       0.88      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3105\n",
      "           1       0.73      0.49      0.59       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.82      0.73      0.76      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.39999999999999997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3105\n",
      "           1       0.75      0.46      0.57       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.83      0.72      0.75      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.44999999999999996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3105\n",
      "           1       0.78      0.43      0.56       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.84      0.71      0.75      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.49999999999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3105\n",
      "           1       0.79      0.39      0.52       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.84      0.69      0.73      3685\n",
      "weighted avg       0.88      0.89      0.87      3685\n",
      "\n",
      "LG with threshold: 0.5499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.94      3105\n",
      "           1       0.81      0.36      0.50       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.85      0.67      0.72      3685\n",
      "weighted avg       0.88      0.89      0.87      3685\n",
      "\n",
      "LG with threshold: 0.5999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93      3105\n",
      "           1       0.82      0.33      0.47       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.66      0.70      3685\n",
      "weighted avg       0.88      0.88      0.86      3685\n",
      "\n",
      "LG with threshold: 0.6499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.81      0.30      0.44       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.65      0.69      3685\n",
      "weighted avg       0.87      0.88      0.86      3685\n",
      "\n",
      "LG with threshold: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.83      0.28      0.41       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.63      0.67      3685\n",
      "weighted avg       0.87      0.88      0.85      3685\n",
      "\n",
      "LG with threshold: 0.7499999999999998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.83      0.26      0.40       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.63      0.66      3685\n",
      "weighted avg       0.87      0.88      0.85      3685\n",
      "\n",
      "LG with threshold: 0.7999999999999998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      3105\n",
      "           1       0.84      0.23      0.36       580\n",
      "\n",
      "    accuracy                           0.87      3685\n",
      "   macro avg       0.86      0.61      0.65      3685\n",
      "weighted avg       0.87      0.87      0.84      3685\n",
      "\n",
      "LG with threshold: 0.8499999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      3105\n",
      "           1       0.87      0.20      0.33       580\n",
      "\n",
      "    accuracy                           0.87      3685\n",
      "   macro avg       0.87      0.60      0.63      3685\n",
      "weighted avg       0.87      0.87      0.83      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.2, 0.9, 0.05)\n",
    "for threshold in thresholds:\n",
    "    y_pred = y_prob_pred > threshold\n",
    "    print(f'LG with threshold: {threshold}')\n",
    "    #print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710933375004106"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(logmodel, X, y, cv=10, scoring='roc_auc')\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2,  2.4,  4.6,  6.8,  9. , 11.2, 13.4, 15.6, 17.8, 20. ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.2, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LG: Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Type of penalty - Lasso(l1) or Ridge(l2)\n",
    "penalties = ['l1','l2']\n",
    "C_values = np.linspace(0.2, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([ 0.2,  2.4,  4.6,  6.8,  9. , 11.2, 13.4, 15.6, 17.8, 20. ]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Cross-Validation\n",
    "cross_valid = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "params = {'penalty': penalties, 'C': C_values}\n",
    "\n",
    "logmodel2 = LogisticRegression(solver='liblinear')\n",
    "grid = GridSearchCV(estimator=logmodel2, param_grid=params, scoring='recall', n_jobs=-1, cv=cross_valid)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.19, 'penalty': 'l1'}\n",
      "0.8830043757934606\n",
      "LogisticRegression(C=1.19, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z - score Scaler - {-1;1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scal = sc.fit_transform(df.drop(labels=['Revenue'], axis=1))\n",
    "X_scal\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scal, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(12, activation='tanh', kernel_initializer='random_normal', input_dim=X_scal.shape[1]))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(12, activation='tanh', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8598/8598 [==============================] - 1s 86us/step - loss: 0.3668 - accuracy: 0.8647\n",
      "Epoch 2/100\n",
      "8598/8598 [==============================] - 1s 81us/step - loss: 0.2936 - accuracy: 0.8859\n",
      "Epoch 3/100\n",
      "8598/8598 [==============================] - 1s 108us/step - loss: 0.2819 - accuracy: 0.8880\n",
      "Epoch 4/100\n",
      "8598/8598 [==============================] - 1s 117us/step - loss: 0.2718 - accuracy: 0.8894\n",
      "Epoch 5/100\n",
      "8598/8598 [==============================] - 1s 116us/step - loss: 0.2644 - accuracy: 0.8942\n",
      "Epoch 6/100\n",
      "8598/8598 [==============================] - 1s 72us/step - loss: 0.2600 - accuracy: 0.8930\n",
      "Epoch 7/100\n",
      "8598/8598 [==============================] - 1s 79us/step - loss: 0.2564 - accuracy: 0.8944\n",
      "Epoch 8/100\n",
      "8598/8598 [==============================] - 1s 93us/step - loss: 0.2533 - accuracy: 0.8968\n",
      "Epoch 9/100\n",
      "8598/8598 [==============================] - 1s 84us/step - loss: 0.2514 - accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "8598/8598 [==============================] - 1s 92us/step - loss: 0.2498 - accuracy: 0.8992\n",
      "Epoch 11/100\n",
      "8598/8598 [==============================] - 1s 76us/step - loss: 0.2471 - accuracy: 0.8990\n",
      "Epoch 12/100\n",
      "8598/8598 [==============================] - 1s 94us/step - loss: 0.2453 - accuracy: 0.9009\n",
      "Epoch 13/100\n",
      "8598/8598 [==============================] - 1s 98us/step - loss: 0.2431 - accuracy: 0.9022\n",
      "Epoch 14/100\n",
      "8598/8598 [==============================] - 1s 98us/step - loss: 0.2411 - accuracy: 0.9021\n",
      "Epoch 15/100\n",
      "8598/8598 [==============================] - 1s 97us/step - loss: 0.2392 - accuracy: 0.9017\n",
      "Epoch 16/100\n",
      "8598/8598 [==============================] - 1s 107us/step - loss: 0.2365 - accuracy: 0.9039\n",
      "Epoch 17/100\n",
      "8598/8598 [==============================] - 1s 79us/step - loss: 0.2355 - accuracy: 0.9064\n",
      "Epoch 18/100\n",
      "8598/8598 [==============================] - 1s 68us/step - loss: 0.2340 - accuracy: 0.9063\n",
      "Epoch 19/100\n",
      "8598/8598 [==============================] - 0s 55us/step - loss: 0.2328 - accuracy: 0.9058\n",
      "Epoch 20/100\n",
      "8598/8598 [==============================] - 0s 58us/step - loss: 0.2301 - accuracy: 0.9071\n",
      "Epoch 21/100\n",
      "8598/8598 [==============================] - 1s 76us/step - loss: 0.2292 - accuracy: 0.9089\n",
      "Epoch 22/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.2281 - accuracy: 0.9094\n",
      "Epoch 23/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2263 - accuracy: 0.9088\n",
      "Epoch 24/100\n",
      "8598/8598 [==============================] - 1s 63us/step - loss: 0.2256 - accuracy: 0.9092\n",
      "Epoch 25/100\n",
      "8598/8598 [==============================] - 1s 75us/step - loss: 0.2246 - accuracy: 0.9100\n",
      "Epoch 26/100\n",
      "8598/8598 [==============================] - 1s 68us/step - loss: 0.2227 - accuracy: 0.9097\n",
      "Epoch 27/100\n",
      "8598/8598 [==============================] - 0s 58us/step - loss: 0.2215 - accuracy: 0.9110\n",
      "Epoch 28/100\n",
      "8598/8598 [==============================] - 1s 60us/step - loss: 0.2205 - accuracy: 0.9096\n",
      "Epoch 29/100\n",
      "8598/8598 [==============================] - 1s 71us/step - loss: 0.2193 - accuracy: 0.9123\n",
      "Epoch 30/100\n",
      "8598/8598 [==============================] - 1s 59us/step - loss: 0.2179 - accuracy: 0.9147\n",
      "Epoch 31/100\n",
      "8598/8598 [==============================] - 1s 61us/step - loss: 0.2164 - accuracy: 0.9128\n",
      "Epoch 32/100\n",
      "8598/8598 [==============================] - 1s 62us/step - loss: 0.2159 - accuracy: 0.9140\n",
      "Epoch 33/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2142 - accuracy: 0.9159\n",
      "Epoch 34/100\n",
      "8598/8598 [==============================] - 1s 107us/step - loss: 0.2132 - accuracy: 0.9163\n",
      "Epoch 35/100\n",
      "8598/8598 [==============================] - 1s 71us/step - loss: 0.2122 - accuracy: 0.9153\n",
      "Epoch 36/100\n",
      "8598/8598 [==============================] - 1s 109us/step - loss: 0.2104 - accuracy: 0.9153\n",
      "Epoch 37/100\n",
      "8598/8598 [==============================] - 1s 62us/step - loss: 0.2102 - accuracy: 0.9163\n",
      "Epoch 38/100\n",
      "8598/8598 [==============================] - 0s 56us/step - loss: 0.2088 - accuracy: 0.9173\n",
      "Epoch 39/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2083 - accuracy: 0.9170\n",
      "Epoch 40/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2072 - accuracy: 0.9181\n",
      "Epoch 41/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2062 - accuracy: 0.9166\n",
      "Epoch 42/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2048 - accuracy: 0.9165\n",
      "Epoch 43/100\n",
      "8598/8598 [==============================] - 0s 57us/step - loss: 0.2042 - accuracy: 0.9182\n",
      "Epoch 44/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2036 - accuracy: 0.9187\n",
      "Epoch 45/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2030 - accuracy: 0.9180\n",
      "Epoch 46/100\n",
      "8598/8598 [==============================] - 1s 67us/step - loss: 0.2014 - accuracy: 0.9189\n",
      "Epoch 47/100\n",
      "8598/8598 [==============================] - 1s 100us/step - loss: 0.2017 - accuracy: 0.9181\n",
      "Epoch 48/100\n",
      "8598/8598 [==============================] - 1s 97us/step - loss: 0.1995 - accuracy: 0.9177\n",
      "Epoch 49/100\n",
      "8598/8598 [==============================] - 1s 122us/step - loss: 0.2000 - accuracy: 0.9206\n",
      "Epoch 50/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.1988 - accuracy: 0.9200\n",
      "Epoch 51/100\n",
      "8598/8598 [==============================] - 1s 83us/step - loss: 0.1980 - accuracy: 0.9196\n",
      "Epoch 52/100\n",
      "8598/8598 [==============================] - 1s 108us/step - loss: 0.1973 - accuracy: 0.9236\n",
      "Epoch 53/100\n",
      "8598/8598 [==============================] - 1s 61us/step - loss: 0.1976 - accuracy: 0.9195\n",
      "Epoch 54/100\n",
      "8598/8598 [==============================] - 1s 100us/step - loss: 0.1962 - accuracy: 0.9199\n",
      "Epoch 55/100\n",
      "8598/8598 [==============================] - 0s 57us/step - loss: 0.1956 - accuracy: 0.9215\n",
      "Epoch 56/100\n",
      "8598/8598 [==============================] - 1s 70us/step - loss: 0.1943 - accuracy: 0.9200\n",
      "Epoch 57/100\n",
      "8598/8598 [==============================] - 1s 76us/step - loss: 0.1939 - accuracy: 0.9210\n",
      "Epoch 58/100\n",
      "8598/8598 [==============================] - 1s 78us/step - loss: 0.1936 - accuracy: 0.9214\n",
      "Epoch 59/100\n",
      "8598/8598 [==============================] - 1s 76us/step - loss: 0.1920 - accuracy: 0.9194\n",
      "Epoch 60/100\n",
      "8598/8598 [==============================] - 0s 55us/step - loss: 0.1922 - accuracy: 0.9211\n",
      "Epoch 61/100\n",
      "8598/8598 [==============================] - 1s 63us/step - loss: 0.1916 - accuracy: 0.9222\n",
      "Epoch 62/100\n",
      "8598/8598 [==============================] - 1s 71us/step - loss: 0.1911 - accuracy: 0.9196\n",
      "Epoch 63/100\n",
      "8598/8598 [==============================] - 1s 63us/step - loss: 0.1901 - accuracy: 0.9214\n",
      "Epoch 64/100\n",
      "8598/8598 [==============================] - 1s 66us/step - loss: 0.1891 - accuracy: 0.9211\n",
      "Epoch 65/100\n",
      "8598/8598 [==============================] - 1s 71us/step - loss: 0.1888 - accuracy: 0.9225\n",
      "Epoch 66/100\n",
      "8598/8598 [==============================] - 1s 77us/step - loss: 0.1884 - accuracy: 0.9235\n",
      "Epoch 67/100\n",
      "8598/8598 [==============================] - 1s 77us/step - loss: 0.1877 - accuracy: 0.9218\n",
      "Epoch 68/100\n",
      "8598/8598 [==============================] - 1s 78us/step - loss: 0.1872 - accuracy: 0.9229\n",
      "Epoch 69/100\n",
      "8598/8598 [==============================] - 1s 78us/step - loss: 0.1869 - accuracy: 0.9231\n",
      "Epoch 70/100\n",
      "8598/8598 [==============================] - 1s 78us/step - loss: 0.1865 - accuracy: 0.9234\n",
      "Epoch 71/100\n",
      "8598/8598 [==============================] - 1s 78us/step - loss: 0.1856 - accuracy: 0.9236\n",
      "Epoch 72/100\n",
      "8598/8598 [==============================] - 1s 78us/step - loss: 0.1848 - accuracy: 0.9234\n",
      "Epoch 73/100\n",
      "8598/8598 [==============================] - 1s 80us/step - loss: 0.1837 - accuracy: 0.9238\n",
      "Epoch 74/100\n",
      "8598/8598 [==============================] - 1s 86us/step - loss: 0.1839 - accuracy: 0.9228\n",
      "Epoch 75/100\n",
      "8598/8598 [==============================] - 1s 76us/step - loss: 0.1838 - accuracy: 0.9223\n",
      "Epoch 76/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.1832 - accuracy: 0.9242\n",
      "Epoch 77/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.1823 - accuracy: 0.9237\n",
      "Epoch 78/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.1812 - accuracy: 0.9239\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.1816 - accuracy: 0.9247\n",
      "Epoch 80/100\n",
      "8598/8598 [==============================] - 1s 61us/step - loss: 0.1811 - accuracy: 0.9228\n",
      "Epoch 81/100\n",
      "8598/8598 [==============================] - 1s 71us/step - loss: 0.1801 - accuracy: 0.9229\n",
      "Epoch 82/100\n",
      "8598/8598 [==============================] - 1s 62us/step - loss: 0.1794 - accuracy: 0.9247\n",
      "Epoch 83/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.1796 - accuracy: 0.9239\n",
      "Epoch 84/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.1782 - accuracy: 0.9251\n",
      "Epoch 85/100\n",
      "8598/8598 [==============================] - 0s 56us/step - loss: 0.1775 - accuracy: 0.9253\n",
      "Epoch 86/100\n",
      "8598/8598 [==============================] - 1s 64us/step - loss: 0.1776 - accuracy: 0.9246\n",
      "Epoch 87/100\n",
      "8598/8598 [==============================] - 1s 64us/step - loss: 0.1768 - accuracy: 0.9244\n",
      "Epoch 88/100\n",
      "8598/8598 [==============================] - 1s 81us/step - loss: 0.1777 - accuracy: 0.9259\n",
      "Epoch 89/100\n",
      "8598/8598 [==============================] - 1s 88us/step - loss: 0.1759 - accuracy: 0.9238\n",
      "Epoch 90/100\n",
      "8598/8598 [==============================] - 1s 86us/step - loss: 0.1762 - accuracy: 0.9236\n",
      "Epoch 91/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.1751 - accuracy: 0.9243\n",
      "Epoch 92/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.1749 - accuracy: 0.9234\n",
      "Epoch 93/100\n",
      "8598/8598 [==============================] - 1s 60us/step - loss: 0.1744 - accuracy: 0.9254\n",
      "Epoch 94/100\n",
      "8598/8598 [==============================] - 1s 78us/step - loss: 0.1743 - accuracy: 0.9268\n",
      "Epoch 95/100\n",
      "8598/8598 [==============================] - 1s 92us/step - loss: 0.1732 - accuracy: 0.9261\n",
      "Epoch 96/100\n",
      "8598/8598 [==============================] - 1s 97us/step - loss: 0.1738 - accuracy: 0.9272\n",
      "Epoch 97/100\n",
      "8598/8598 [==============================] - 1s 77us/step - loss: 0.1729 - accuracy: 0.9254\n",
      "Epoch 98/100\n",
      "8598/8598 [==============================] - 1s 77us/step - loss: 0.1719 - accuracy: 0.9268\n",
      "Epoch 99/100\n",
      "8598/8598 [==============================] - 1s 86us/step - loss: 0.1718 - accuracy: 0.9268\n",
      "Epoch 100/100\n",
      "8598/8598 [==============================] - 1s 93us/step - loss: 0.1711 - accuracy: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa4c85d3b10>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8598/8598 [==============================] - 0s 8us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6930214621128384, 0.5132588744163513]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_prod_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG with threshold: 0.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      3105\n",
      "           1       0.49      0.80      0.61       580\n",
      "\n",
      "    accuracy                           0.84      3685\n",
      "   macro avg       0.73      0.82      0.76      3685\n",
      "weighted avg       0.89      0.84      0.85      3685\n",
      "\n",
      "LG with threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      3105\n",
      "           1       0.62      0.72      0.67       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.79      0.82      0.80      3685\n",
      "weighted avg       0.90      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      3105\n",
      "           1       0.67      0.61      0.64       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.80      0.78      0.79      3685\n",
      "weighted avg       0.89      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      3105\n",
      "           1       0.70      0.54      0.61       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.81      0.75      0.77      3685\n",
      "weighted avg       0.88      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.3500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3105\n",
      "           1       0.73      0.49      0.59       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.82      0.73      0.76      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.40000000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3105\n",
      "           1       0.75      0.46      0.57       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.83      0.72      0.75      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.45000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3105\n",
      "           1       0.78      0.43      0.56       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.84      0.71      0.75      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.5000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3105\n",
      "           1       0.79      0.39      0.52       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.84      0.69      0.73      3685\n",
      "weighted avg       0.88      0.89      0.87      3685\n",
      "\n",
      "LG with threshold: 0.5500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.94      3105\n",
      "           1       0.81      0.36      0.50       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.85      0.67      0.72      3685\n",
      "weighted avg       0.88      0.89      0.87      3685\n",
      "\n",
      "LG with threshold: 0.6000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93      3105\n",
      "           1       0.82      0.33      0.47       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.66      0.70      3685\n",
      "weighted avg       0.88      0.88      0.86      3685\n",
      "\n",
      "LG with threshold: 0.6500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.81      0.30      0.44       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.65      0.69      3685\n",
      "weighted avg       0.87      0.88      0.86      3685\n",
      "\n",
      "LG with threshold: 0.7000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.83      0.28      0.41       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.63      0.67      3685\n",
      "weighted avg       0.87      0.88      0.85      3685\n",
      "\n",
      "LG with threshold: 0.7500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.83      0.26      0.40       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.63      0.66      3685\n",
      "weighted avg       0.87      0.88      0.85      3685\n",
      "\n",
      "LG with threshold: 0.8000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      3105\n",
      "           1       0.84      0.23      0.36       580\n",
      "\n",
      "    accuracy                           0.87      3685\n",
      "   macro avg       0.86      0.61      0.65      3685\n",
      "weighted avg       0.87      0.87      0.84      3685\n",
      "\n",
      "LG with threshold: 0.8500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      3105\n",
      "           1       0.87      0.20      0.33       580\n",
      "\n",
      "    accuracy                           0.87      3685\n",
      "   macro avg       0.87      0.60      0.63      3685\n",
      "weighted avg       0.87      0.87      0.83      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.15, 0.9, 0.05)\n",
    "for threshold in thresholds:\n",
    "    y_pred = y_prob_pred > threshold\n",
    "    print(f'LG with threshold: {threshold}')\n",
    "    #print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scal = scaler.fit_transform(df.drop(labels=['Revenue'], axis=1))\n",
    "X_scal\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scal, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8598/8598 [==============================] - 1s 61us/step - loss: 0.4296 - accuracy: 0.8438\n",
      "Epoch 2/100\n",
      "8598/8598 [==============================] - 1s 61us/step - loss: 0.3607 - accuracy: 0.8503\n",
      "Epoch 3/100\n",
      "8598/8598 [==============================] - 1s 69us/step - loss: 0.3270 - accuracy: 0.8673\n",
      "Epoch 4/100\n",
      "8598/8598 [==============================] - 0s 55us/step - loss: 0.3046 - accuracy: 0.8782\n",
      "Epoch 5/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2909 - accuracy: 0.8866\n",
      "Epoch 6/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2825 - accuracy: 0.8892\n",
      "Epoch 7/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2777 - accuracy: 0.8881\n",
      "Epoch 8/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2735 - accuracy: 0.8879\n",
      "Epoch 9/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2695 - accuracy: 0.8918\n",
      "Epoch 10/100\n",
      "8598/8598 [==============================] - 0s 56us/step - loss: 0.2675 - accuracy: 0.8908\n",
      "Epoch 11/100\n",
      "8598/8598 [==============================] - 1s 59us/step - loss: 0.2637 - accuracy: 0.8908\n",
      "Epoch 12/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.2619 - accuracy: 0.8937\n",
      "Epoch 13/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2592 - accuracy: 0.8939\n",
      "Epoch 14/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2573 - accuracy: 0.8921\n",
      "Epoch 15/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2586 - accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2561 - accuracy: 0.8933\n",
      "Epoch 17/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2544 - accuracy: 0.8951\n",
      "Epoch 18/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2526 - accuracy: 0.8947\n",
      "Epoch 19/100\n",
      "8598/8598 [==============================] - 0s 50us/step - loss: 0.2514 - accuracy: 0.8947\n",
      "Epoch 20/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.2493 - accuracy: 0.8972\n",
      "Epoch 21/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2501 - accuracy: 0.8959\n",
      "Epoch 22/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2503 - accuracy: 0.8971\n",
      "Epoch 23/100\n",
      "8598/8598 [==============================] - 1s 61us/step - loss: 0.2478 - accuracy: 0.8965\n",
      "Epoch 24/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2468 - accuracy: 0.8978\n",
      "Epoch 25/100\n",
      "8598/8598 [==============================] - 0s 50us/step - loss: 0.2465 - accuracy: 0.8978\n",
      "Epoch 26/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.2464 - accuracy: 0.8993\n",
      "Epoch 27/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.2463 - accuracy: 0.8987\n",
      "Epoch 28/100\n",
      "8598/8598 [==============================] - 0s 50us/step - loss: 0.2438 - accuracy: 0.8980\n",
      "Epoch 29/100\n",
      "8598/8598 [==============================] - 1s 59us/step - loss: 0.2439 - accuracy: 0.8986\n",
      "Epoch 30/100\n",
      "8598/8598 [==============================] - 0s 57us/step - loss: 0.2427 - accuracy: 0.8977\n",
      "Epoch 31/100\n",
      "8598/8598 [==============================] - 0s 57us/step - loss: 0.2420 - accuracy: 0.8972\n",
      "Epoch 32/100\n",
      "8598/8598 [==============================] - 0s 55us/step - loss: 0.2415 - accuracy: 0.8985\n",
      "Epoch 33/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.2411 - accuracy: 0.8986\n",
      "Epoch 34/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2397 - accuracy: 0.8989\n",
      "Epoch 35/100\n",
      "8598/8598 [==============================] - 0s 52us/step - loss: 0.2389 - accuracy: 0.8997\n",
      "Epoch 36/100\n",
      "8598/8598 [==============================] - 0s 50us/step - loss: 0.2384 - accuracy: 0.9014\n",
      "Epoch 37/100\n",
      "8598/8598 [==============================] - 0s 51us/step - loss: 0.2386 - accuracy: 0.8989\n",
      "Epoch 38/100\n",
      "8598/8598 [==============================] - 0s 53us/step - loss: 0.2364 - accuracy: 0.8996\n",
      "Epoch 39/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2358 - accuracy: 0.8987\n",
      "Epoch 40/100\n",
      "8598/8598 [==============================] - 0s 56us/step - loss: 0.2359 - accuracy: 0.8996\n",
      "Epoch 41/100\n",
      "8598/8598 [==============================] - 0s 54us/step - loss: 0.2340 - accuracy: 0.9010\n",
      "Epoch 42/100\n",
      "8598/8598 [==============================] - 1s 65us/step - loss: 0.2351 - accuracy: 0.8994\n",
      "Epoch 43/100\n",
      "8598/8598 [==============================] - 0s 58us/step - loss: 0.2341 - accuracy: 0.9004\n",
      "Epoch 44/100\n",
      "8598/8598 [==============================] - 0s 55us/step - loss: 0.2325 - accuracy: 0.9004\n",
      "Epoch 45/100\n",
      "8598/8598 [==============================] - 0s 55us/step - loss: 0.2316 - accuracy: 0.9029\n",
      "Epoch 46/100\n",
      "8598/8598 [==============================] - 0s 55us/step - loss: 0.2314 - accuracy: 0.9006\n",
      "Epoch 47/100\n",
      "8598/8598 [==============================] - 1s 59us/step - loss: 0.2297 - accuracy: 0.9024\n",
      "Epoch 48/100\n",
      "8598/8598 [==============================] - 1s 62us/step - loss: 0.2299 - accuracy: 0.9016\n",
      "Epoch 49/100\n",
      "8598/8598 [==============================] - 1s 65us/step - loss: 0.2290 - accuracy: 0.9016\n",
      "Epoch 50/100\n",
      "8598/8598 [==============================] - 1s 79us/step - loss: 0.2280 - accuracy: 0.9027\n",
      "Epoch 51/100\n",
      "8598/8598 [==============================] - 1s 97us/step - loss: 0.2284 - accuracy: 0.9008\n",
      "Epoch 52/100\n",
      "8598/8598 [==============================] - 1s 110us/step - loss: 0.2268 - accuracy: 0.9017\n",
      "Epoch 53/100\n",
      "8598/8598 [==============================] - 1s 92us/step - loss: 0.2255 - accuracy: 0.9028\n",
      "Epoch 54/100\n",
      "8598/8598 [==============================] - 1s 81us/step - loss: 0.2261 - accuracy: 0.9017\n",
      "Epoch 55/100\n",
      "8598/8598 [==============================] - 1s 100us/step - loss: 0.2262 - accuracy: 0.9036\n",
      "Epoch 56/100\n",
      "8598/8598 [==============================] - 1s 101us/step - loss: 0.2241 - accuracy: 0.9023\n",
      "Epoch 57/100\n",
      "8598/8598 [==============================] - 1s 100us/step - loss: 0.2235 - accuracy: 0.9028\n",
      "Epoch 58/100\n",
      "8598/8598 [==============================] - 1s 99us/step - loss: 0.2237 - accuracy: 0.9045\n",
      "Epoch 59/100\n",
      "8598/8598 [==============================] - 1s 68us/step - loss: 0.2229 - accuracy: 0.9028\n",
      "Epoch 60/100\n",
      "8598/8598 [==============================] - 1s 80us/step - loss: 0.2212 - accuracy: 0.9057\n",
      "Epoch 61/100\n",
      "8598/8598 [==============================] - 1s 91us/step - loss: 0.2212 - accuracy: 0.9033\n",
      "Epoch 62/100\n",
      "8598/8598 [==============================] - 1s 96us/step - loss: 0.2197 - accuracy: 0.9038\n",
      "Epoch 63/100\n",
      "8598/8598 [==============================] - 1s 96us/step - loss: 0.2203 - accuracy: 0.9039\n",
      "Epoch 64/100\n",
      "8598/8598 [==============================] - 1s 95us/step - loss: 0.2189 - accuracy: 0.9054\n",
      "Epoch 65/100\n",
      "8598/8598 [==============================] - 1s 96us/step - loss: 0.2188 - accuracy: 0.9037\n",
      "Epoch 66/100\n",
      "8598/8598 [==============================] - 1s 96us/step - loss: 0.2183 - accuracy: 0.9057\n",
      "Epoch 67/100\n",
      "8598/8598 [==============================] - 1s 96us/step - loss: 0.2177 - accuracy: 0.9050\n",
      "Epoch 68/100\n",
      "8598/8598 [==============================] - 1s 105us/step - loss: 0.2173 - accuracy: 0.9053\n",
      "Epoch 69/100\n",
      "8598/8598 [==============================] - 1s 109us/step - loss: 0.2171 - accuracy: 0.9054\n",
      "Epoch 70/100\n",
      "8598/8598 [==============================] - 1s 109us/step - loss: 0.2167 - accuracy: 0.9049\n",
      "Epoch 71/100\n",
      "8598/8598 [==============================] - 1s 121us/step - loss: 0.2163 - accuracy: 0.9057\n",
      "Epoch 72/100\n",
      "8598/8598 [==============================] - 1s 127us/step - loss: 0.2149 - accuracy: 0.9072\n",
      "Epoch 73/100\n",
      "8598/8598 [==============================] - 1s 120us/step - loss: 0.2161 - accuracy: 0.9053\n",
      "Epoch 74/100\n",
      "8598/8598 [==============================] - 1s 65us/step - loss: 0.2156 - accuracy: 0.9073\n",
      "Epoch 75/100\n",
      "8598/8598 [==============================] - 1s 90us/step - loss: 0.2149 - accuracy: 0.9064\n",
      "Epoch 76/100\n",
      "8598/8598 [==============================] - 1s 89us/step - loss: 0.2143 - accuracy: 0.9071\n",
      "Epoch 77/100\n",
      "8598/8598 [==============================] - 1s 88us/step - loss: 0.2138 - accuracy: 0.9071\n",
      "Epoch 78/100\n",
      "8598/8598 [==============================] - 1s 88us/step - loss: 0.2140 - accuracy: 0.9073\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8598/8598 [==============================] - 1s 101us/step - loss: 0.2135 - accuracy: 0.9068\n",
      "Epoch 80/100\n",
      "8598/8598 [==============================] - 1s 123us/step - loss: 0.2121 - accuracy: 0.9050\n",
      "Epoch 81/100\n",
      "8598/8598 [==============================] - 1s 99us/step - loss: 0.2119 - accuracy: 0.9071\n",
      "Epoch 82/100\n",
      "8598/8598 [==============================] - 1s 125us/step - loss: 0.2124 - accuracy: 0.9059\n",
      "Epoch 83/100\n",
      "8598/8598 [==============================] - 1s 136us/step - loss: 0.2125 - accuracy: 0.9063\n",
      "Epoch 84/100\n",
      "8598/8598 [==============================] - 1s 99us/step - loss: 0.2124 - accuracy: 0.9077\n",
      "Epoch 85/100\n",
      "8598/8598 [==============================] - 1s 125us/step - loss: 0.2113 - accuracy: 0.9073\n",
      "Epoch 86/100\n",
      "8598/8598 [==============================] - 1s 98us/step - loss: 0.2115 - accuracy: 0.9081\n",
      "Epoch 87/100\n",
      "8598/8598 [==============================] - 1s 98us/step - loss: 0.2118 - accuracy: 0.9078\n",
      "Epoch 88/100\n",
      "8598/8598 [==============================] - 1s 132us/step - loss: 0.2098 - accuracy: 0.9086\n",
      "Epoch 89/100\n",
      "8598/8598 [==============================] - 1s 152us/step - loss: 0.2110 - accuracy: 0.9078\n",
      "Epoch 90/100\n",
      "8598/8598 [==============================] - 1s 136us/step - loss: 0.2102 - accuracy: 0.9085\n",
      "Epoch 91/100\n",
      "8598/8598 [==============================] - 1s 100us/step - loss: 0.2103 - accuracy: 0.9080\n",
      "Epoch 92/100\n",
      "8598/8598 [==============================] - 1s 135us/step - loss: 0.2094 - accuracy: 0.9097\n",
      "Epoch 93/100\n",
      "8598/8598 [==============================] - 1s 133us/step - loss: 0.2094 - accuracy: 0.9087\n",
      "Epoch 94/100\n",
      "8598/8598 [==============================] - 1s 132us/step - loss: 0.2099 - accuracy: 0.9094\n",
      "Epoch 95/100\n",
      "8598/8598 [==============================] - 1s 133us/step - loss: 0.2069 - accuracy: 0.9081\n",
      "Epoch 96/100\n",
      "8598/8598 [==============================] - 1s 86us/step - loss: 0.2093 - accuracy: 0.9082\n",
      "Epoch 97/100\n",
      "8598/8598 [==============================] - 1s 106us/step - loss: 0.2091 - accuracy: 0.9080\n",
      "Epoch 98/100\n",
      "8598/8598 [==============================] - 1s 127us/step - loss: 0.2080 - accuracy: 0.9085\n",
      "Epoch 99/100\n",
      "8598/8598 [==============================] - 1s 125us/step - loss: 0.2079 - accuracy: 0.9093\n",
      "Epoch 100/100\n",
      "8598/8598 [==============================] - 1s 173us/step - loss: 0.2083 - accuracy: 0.9103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa4c8060e10>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(12, activation='relu', kernel_initializer='random_normal', input_dim=X_scal.shape[1]))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(12, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prod_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG with threshold: 0.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90      3105\n",
      "           1       0.49      0.80      0.61       580\n",
      "\n",
      "    accuracy                           0.84      3685\n",
      "   macro avg       0.73      0.82      0.76      3685\n",
      "weighted avg       0.89      0.84      0.85      3685\n",
      "\n",
      "LG with threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      3105\n",
      "           1       0.62      0.72      0.67       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.79      0.82      0.80      3685\n",
      "weighted avg       0.90      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      3105\n",
      "           1       0.67      0.61      0.64       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.80      0.78      0.79      3685\n",
      "weighted avg       0.89      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      3105\n",
      "           1       0.70      0.54      0.61       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.81      0.75      0.77      3685\n",
      "weighted avg       0.88      0.89      0.89      3685\n",
      "\n",
      "LG with threshold: 0.3500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3105\n",
      "           1       0.73      0.49      0.59       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.82      0.73      0.76      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.40000000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      3105\n",
      "           1       0.75      0.46      0.57       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.83      0.72      0.75      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.45000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3105\n",
      "           1       0.78      0.43      0.56       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.84      0.71      0.75      3685\n",
      "weighted avg       0.88      0.89      0.88      3685\n",
      "\n",
      "LG with threshold: 0.5000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      3105\n",
      "           1       0.79      0.39      0.52       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.84      0.69      0.73      3685\n",
      "weighted avg       0.88      0.89      0.87      3685\n",
      "\n",
      "LG with threshold: 0.5500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.94      3105\n",
      "           1       0.81      0.36      0.50       580\n",
      "\n",
      "    accuracy                           0.89      3685\n",
      "   macro avg       0.85      0.67      0.72      3685\n",
      "weighted avg       0.88      0.89      0.87      3685\n",
      "\n",
      "LG with threshold: 0.6000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93      3105\n",
      "           1       0.82      0.33      0.47       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.66      0.70      3685\n",
      "weighted avg       0.88      0.88      0.86      3685\n",
      "\n",
      "LG with threshold: 0.6500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.81      0.30      0.44       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.65      0.69      3685\n",
      "weighted avg       0.87      0.88      0.86      3685\n",
      "\n",
      "LG with threshold: 0.7000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.83      0.28      0.41       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.63      0.67      3685\n",
      "weighted avg       0.87      0.88      0.85      3685\n",
      "\n",
      "LG with threshold: 0.7500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      3105\n",
      "           1       0.83      0.26      0.40       580\n",
      "\n",
      "    accuracy                           0.88      3685\n",
      "   macro avg       0.85      0.63      0.66      3685\n",
      "weighted avg       0.87      0.88      0.85      3685\n",
      "\n",
      "LG with threshold: 0.8000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      3105\n",
      "           1       0.84      0.23      0.36       580\n",
      "\n",
      "    accuracy                           0.87      3685\n",
      "   macro avg       0.86      0.61      0.65      3685\n",
      "weighted avg       0.87      0.87      0.84      3685\n",
      "\n",
      "LG with threshold: 0.8500000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93      3105\n",
      "           1       0.87      0.20      0.33       580\n",
      "\n",
      "    accuracy                           0.87      3685\n",
      "   macro avg       0.87      0.60      0.63      3685\n",
      "weighted avg       0.87      0.87      0.83      3685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.15, 0.9, 0.05)\n",
    "for threshold in thresholds:\n",
    "    y_pred = y_prob_pred > threshold\n",
    "    print(f'LG with threshold: {threshold}')\n",
    "    #print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
